/**
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * ğŸ§  WHAT IS RABBITMQ STREAM?
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * âœ… RabbitMQ Stream is a **high-throughput, append-only log** system:
 *
 * - Ideal for event sourcing, log aggregation, time-series pipelines.
 * - Allows consumers to replay messages (not just "once-and-gone" like queues).
 * - Supports very large data retention (gigabytes to terabytes).
 *
 * ğŸ†š Compared to traditional queues:
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚ Feature            â”‚ Classic Queues        | Streams              â”‚
 * â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
 * â”‚ Message Storage    â”‚ In-memory + disk      | Append-only log      â”‚
 * â”‚ Consumption Model  â”‚ Push-only             | Replay possible      â”‚
 * â”‚ Throughput         â”‚ Medium                | Very High            â”‚
 * â”‚ Retention          â”‚ TTL-based (short)     | Size/time-based      â”‚
 * â”‚ Use Cases          â”‚ Tasks, Jobs           | Logs, Events         â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *
 * ğŸ§¾ Real-world example:
 *  A system publishes log entries to a stream:
 *    - One consumer stores to DB
 *    - Another prints to terminal
 *    - Both can replay past events anytime
 */

const rabbit = require("rabbitmq-stream-js-client");

/**
 * Producer sends a single message to a stream.
 */
(async () => {
  const streamName = "hello-nodejs-stream";

  console.log("ğŸ”Œ Connecting to RabbitMQ Stream...");
  const client = await rabbit.connect({
    hostname: "localhost",
    port: 5552,
    username: "guest",
    password: "guest",
    vhost: "/",
  });

  console.log("ğŸ“¦ Creating stream (if not exists)...");
  await client.createStream({
    stream: streamName,
    arguments: {
      "max-length-bytes": 5 * 1024 * 1024 * 1024, // 5GB retention
    },
  });

  const publisher = await client.declarePublisher({ stream: streamName });

  const message = "ğŸ”¥ Hello from RabbitMQ Stream!";
  console.log("ğŸ“¤ Sending message...");
  await publisher.send(Buffer.from(message));

  console.log("âœ… Message sent:", message);

  await client.close();
})();

const rabbit = require("rabbitmq-stream-js-client");

/**
 * Consumer reads messages from the stream (starting from beginning).
 */
(async () => {
  const streamName = "hello-nodejs-stream";

  console.log("ğŸ”Œ Connecting to RabbitMQ Stream...");
  const client = await rabbit.connect({
    hostname: "localhost",
    port: 5552,
    username: "guest",
    password: "guest",
    vhost: "/",
  });

  console.log("ğŸ“¦ Ensuring stream exists...");
  await client.createStream({
    stream: streamName,
    arguments: {
      "max-length-bytes": 5 * 1024 * 1024 * 1024, // same 5GB limit
    },
  });

  console.log("ğŸ“¥ Subscribing to stream from first message...");
  await client.declareConsumer(
    {
      stream: streamName,
      offset: rabbit.Offset.first(), // ğŸ‘ˆ consume from beginning
    },
    (msg) => {
      console.log("ğŸ“¨ Received message:", msg.content.toString());
    }
  );
})();

//* SETUP & USAGE
// # 1. Initialize project
// npm init -y

// # 2. Install RabbitMQ stream client
// npm install rabbitmq-stream-js-client

// # 3. Add these scripts to package.json (optional)
// # "scripts": {
// #   "send": "node send.js",
// #   "receive": "node receive.js"
// # }

// # 4. Start RabbitMQ with Streams enabled (via Docker)
// docker run -it --rm --name rabbitmq -p 5552:5552 -p 15672:15672 -p 5672:5672 \
//   -e RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS='-rabbitmq_stream advertised_host localhost' \
//   rabbitmq:4-management

// # Enable stream plugin:
// docker exec rabbitmq rabbitmq-plugins enable rabbitmq_stream rabbitmq_stream_management

// # 5. Run consumer first
// node receive.js

// # 6. In another terminal, run producer
// node send.js

/**
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * ğŸ§  RABBITMQ STREAMS â€” OVERVIEW, USE CASES, PROS & CONS
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * ğŸ“¦ WHAT ARE RABBITMQ STREAMS?
 * RabbitMQ Streams are a high-throughput, durable, and replayable
 * messaging feature designed for **event streaming**, introduced in RabbitMQ 3.9.
 * Unlike traditional queues (where messages are consumed once), streams act
 * like an **append-only log** â€” allowing multiple consumers to read from
 * any offset (start, latest, etc.).
 *
 * ğŸ”¥ WHY USE STREAMS?
 * Traditional queues are great for job processing (one-time tasks),
 * but fall short when you need:
 *   â†’ Replayable history of messages
 *   â†’ Massive data throughput
 *   â†’ Time-based or size-based retention
 *   â†’ Real-time AND historical event consumption
 *
 * ğŸ§¾ REAL-WORLD EXAMPLES:
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚ ğŸ“Š Event Sourcing & Audit Logs                              â”‚
 * â”‚     - Persist every user action or system event             â”‚
 * â”‚                                                             â”‚
 * â”‚ ğŸ“ˆ Metrics & Monitoring Pipelines                           â”‚
 * â”‚     - Stream server metrics (CPU, memory, errors...)        â”‚
 * â”‚                                                             â”‚
 * â”‚ ğŸ“¡ IoT or Sensor Data                                       â”‚
 * â”‚     - Collect readings from thousands of sensors            â”‚
 * â”‚                                                             â”‚
 * â”‚ ğŸ’¬ Chat & Notification Streams                              â”‚
 * â”‚     - Replay missed messages for new/late consumers         â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *
 * âœ… PROS:
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * âœ” Super high throughput (millions of msgs/sec)
 * âœ” Replay support â€” fetch from start, or a specific offset
 * âœ” Durable storage â€” configurable (e.g. 5GB, 7 days, etc.)
 * âœ” Multiple consumers per stream
 * âœ” Ideal for decoupled, observable, scalable systems
 *
 * âš ï¸ CONS:
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * âŒ More complex than basic queues
 * âŒ Higher disk usage (messages retained longer)
 * âŒ Requires stream-specific ports (default: 5552)
 * âŒ Not all RabbitMQ clients support Streams yet
 *
 * ğŸ§  TL;DR
 * Use RabbitMQ Streams if:
 * â†’ You need to **consume and replay** messages
 * â†’ You deal with **large volumes of continuous events**
 * â†’ You want **durable logs** with high performance
 */
